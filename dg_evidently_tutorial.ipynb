{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "cell1",
    "collapsed": false
   },
   "source": "# Import python packages\nimport pandas as pd\nimport numpy as np\nimport wheel_loader\nimport os\n\n# Add custom wheels (if any)\nwheel_loader.add_wheels()\n\nfrom evidently import ColumnMapping\n\nfrom evidently.report import Report\nfrom evidently.metrics.base_metric import generate_column_metrics\nfrom evidently.metric_preset import DataDriftPreset, TargetDriftPreset\nfrom evidently.metrics import *\n\nfrom evidently.test_suite import TestSuite\nfrom evidently.tests.base_test import generate_column_tests\nfrom evidently.test_preset import DataStabilityTestPreset, NoTargetPerformanceTestPreset\nfrom evidently.tests import *\n\n# We can also use Snowpark for our analyses!\n# Get an active Snowpark session\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "30a148e2-f285-4bce-a665-5e65c67718e0",
   "metadata": {
    "language": "python",
    "name": "cell2"
   },
   "outputs": [],
   "source": "# Function to fetch data from Snowflake and convert to pandas DataFrame\ndef get_snowflake_data(session, table_name):\n    query = f\"\"\"\n    SELECT * FROM {table_name}\n    \"\"\"\n    snow_df = session.sql(query)\n    return snow_df.to_pandas()\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "52ee88f6-12bf-4742-aceb-c5271274f377",
   "metadata": {
    "language": "python",
    "name": "cell3",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "housing_data = get_snowflake_data(session, 'DG_RAW_TST_DB.DG.HOUSING_DATA')",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "55f0e2f2-ee3c-452c-8a37-e3f97a3af8b6",
   "metadata": {
    "language": "python",
    "name": "cell4",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "housing_data.head()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e2587fa4-ed1e-4df8-9e9d-a36c07ac7c9c",
   "metadata": {
    "language": "python",
    "name": "cell5",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "housing_data.rename(columns={'MEDHOUSEVAL': 'TARGET'}, inplace=True)\nhousing_data['PREDICTION'] = housing_data['TARGET'].values + np.random.normal(0, 5, housing_data.shape[0])",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "aac64271-3a38-4357-9a53-ca268d182e0d",
   "metadata": {
    "language": "python",
    "name": "cell6",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "reference = housing_data.sample(n=5000, replace=False)\ncurrent = housing_data.sample(n=5000, replace=False)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "44e65e69-ed77-42a4-94ef-581842682c4d",
   "metadata": {
    "language": "python",
    "name": "cell7",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "report = Report(metrics=[\n    DataDriftPreset(), \n])\n\nreport.run(reference_data=reference, current_data=current)\nreport",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "205d0711-e594-482c-81f6-9a8e190efd7e",
   "metadata": {
    "language": "python",
    "name": "cell8",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "report.show()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fbcf89e5-78b8-4c99-ba49-ca44ade5dd5a",
   "metadata": {
    "language": "python",
    "name": "cell9",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "#report.save_html('@DG_RAW_TST_DB.DG.HTML')",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6478191e-98dc-415c-815c-19cee5c89458",
   "metadata": {
    "language": "python",
    "name": "cell10",
    "collapsed": false
   },
   "outputs": [],
   "source": "report = Report(metrics=[\n    ColumnSummaryMetric(column_name='AVEROOMS'),\n    ColumnQuantileMetric(column_name='AVEROOMS', quantile=0.25),\n    ColumnDriftMetric(column_name='AVEROOMS')\n])\n\nreport.run(reference_data=reference, current_data=current)\nreport",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "aea630fb-718b-4d03-be26-380a8db53ca7",
   "metadata": {
    "language": "python",
    "name": "cell11",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "report = Report(metrics=[\n    generate_column_metrics(ColumnQuantileMetric, parameters={'quantile':0.25}, columns=['AVEROOMS', 'AVEBEDRMS']),\n])\n\nreport.run(reference_data=reference, current_data=current)\nreport",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "81aa5409-1ccc-44ae-a770-80009d1f7b60",
   "metadata": {
    "language": "python",
    "name": "cell12",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "report = Report(metrics=[\n    ColumnSummaryMetric(column_name='AVEROOMS'),\n    generate_column_metrics(ColumnQuantileMetric, parameters={'quantile':0.25}, columns='num'),\n    DataDriftPreset()\n])\n\nreport.run(reference_data=reference, current_data=current)\nreport",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ed4a71d9-794f-435f-82ec-7a424d4302be",
   "metadata": {
    "language": "sql",
    "name": "cell13",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "--CREATE STAGE IF NOT EXISTS HTML;\nCREATE OR REPLACE STAGE HTML;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1a622c01-047f-4805-9784-abfba74989d8",
   "metadata": {
    "language": "python",
    "name": "cell15"
   },
   "outputs": [],
   "source": "from datetime import datetime\nimport pytz\n\ndef upload_report_to_stage(report, stage_name='HTML'):\n    # Define the timezone\n    tz = pytz.timezone('UTC')  # Change 'UTC' to your desired timezone if necessary\n\n    # Generate timestamps\n    timestamp = datetime.now(tz)\n    timestamp_str = timestamp.strftime('%Y_%m_%d_%H_%M_%S')\n    date_path = timestamp.strftime('%Y/%m/%d/')\n\n    # Define file paths\n    local_filename = f\"/tmp/{timestamp_str}.html\"\n    stage_path = f\"@{stage_name}/report\"\n    stage_filename = f\"{stage_path}{timestamp_str}.html\"\n\n    try:\n        # Save the report locally\n        report.save_html(local_filename)\n        \n        # Upload the file to Snowflake stage\n        result = session.file.put(local_filename, stage_path, auto_compress=False, overwrite=True)\n        \n        # Check the result of the put operation\n        for file_result in result:\n            if file_result.status != 'UPLOADED':\n                print(f\"Upload failed: {file_result.message}\")\n            else:\n                print(f\"Successfully uploaded to {stage_filename}\")\n        \n        # Get the download URL\n        download_url = session.sql(f\"SELECT GET_PRESIGNED_URL('@{stage_name}', 'report/{date_path}{timestamp_str}.html') AS DOWNLOAD_LINK\").collect()[0]['DOWNLOAD_LINK']\n        print(f\"Download URL: {download_url}\")\n\n        # Verify the file exists in the stage\n        list_result = session.sql(f\"LIST {stage_filename}\").collect()\n        if not list_result:\n            print(f\"Warning: File not found in stage after upload: {stage_filename}\")\n        else:\n            print(f\"File found in stage: {list_result[0]}\")\n\n    except Exception as e:\n        print(f\"An error occurred: {str(e)}\")\n\n    return stage_filename, download_url\n\n# Usage\nstage_filename, download_url = upload_report_to_stage(report)\nprint(f\"Stage filename: {stage_filename}\")\nprint(f\"Download URL: {download_url}\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9c7e7e94-71d9-4a37-a368-27b7e120f745",
   "metadata": {
    "language": "python",
    "name": "cell19",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# # CLEAN UP\n# def cleanup_incorrect_files(stage_name='HTML'):\n#     # List all files in the stage\n#     all_files = session.sql(f\"LIST @{stage_name}\").collect()\n    \n#     for file in all_files:\n#         file_path = file['name']\n#         if file_path.count('.html') > 1:  # Check for duplicated .html in the path\n#             # Construct the removal command\n#             remove_command = f\"REMOVE @{stage_name}/{file_path}\"\n#             print(f\"Removing incorrect file: {file_path}\")\n#             session.sql(remove_command).collect()\n\n# # Run the cleanup\n# cleanup_incorrect_files()\n\n# # Verify the cleanup\n# print(\"Remaining files in stage:\")\n# remaining_files = session.sql(\"LIST @HTML\").collect()\n# for file in remaining_files:\n#     print(file['name'])",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "336e5e69-4bfe-4cbc-b456-9473669bd4a2",
   "metadata": {
    "name": "cell16",
    "collapsed": false
   },
   "source": "# TROUBLE SHOOT"
  },
  {
   "cell_type": "code",
   "id": "e7f75b9c-c3f1-4542-b403-015a4c6d22b0",
   "metadata": {
    "language": "python",
    "name": "cell17",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# List files in the HTML stage\nresult = session.sql(\"LIST @HTML\").collect()\nfor row in result:\n    print(row)\n\n# If you want to check a specific path within the stage:\nspecific_path = \"LIST @HTML/report/2024/08/06/\"\nresult = session.sql(specific_path).collect()\nfor row in result:\n    print(row)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "01febc18-d047-4238-9ab0-047230d7ead8",
   "metadata": {
    "name": "cell14",
    "collapsed": false
   },
   "source": "# STREAMLIT"
  },
  {
   "cell_type": "code",
   "id": "c2cd5e89-81e3-44e6-b578-6683c936685e",
   "metadata": {
    "language": "python",
    "name": "cell18"
   },
   "outputs": [],
   "source": "import streamlit as st\nimport snowflake.snowpark as snowpark\nfrom snowflake.snowpark.functions import udf, lit\nfrom snowflake.snowpark.types import StringType\nimport base64\n\n# Ensure you have an active Snowpark session\n\n\n@st.cache_data\ndef get_html_content(stage_path):\n    try:\n        # First, check if the file exists\n        file_exists = session.sql(f\"LIST @DG_RAW_TST_DB.DG.HTML/{stage_path}\").collect()\n        if not file_exists:\n            return None, f\"File not found: {stage_path}\"\n\n        # If file exists, get the presigned URL\n        url_result = session.sql(f\"SELECT GET_PRESIGNED_URL('@DG_RAW_TST_DB.DG.HTML', '{stage_path}') as file_url\").collect()\n        if not url_result:\n            return None, \"Failed to generate presigned URL\"\n        \n        file_url = url_result[0]['FILE_URL']\n\n        # UDF to read file content\n        @udf(name=\"read_file_udf\", is_permanent=False, stage_location=\"@DG_RAW_TST_DB.DG.HTML\", packages=['requests'])\n        def read_file(url: str) -> str:\n            import requests\n            try:\n                response = requests.get(url)\n                response.raise_for_status()\n                return response.text\n            except requests.RequestException as e:\n                return f\"Error fetching content: {str(e)}\"\n\n        # Create a DataFrame with the URL and apply the UDF\n        df = session.create_dataframe([file_url], schema=[\"url\"])\n        result = df.select(read_file(\"url\").alias(\"content\")).collect()\n\n        if not result:\n            return None, \"Failed to read file content\"\n        \n        return result[0]['CONTENT'], None  # Return content and no error\n    except Exception as e:\n        return None, f\"An error occurred: {str(e)}\"\n\nst.title(\"HTML Report Viewer\")\n\n# List available reports\ntry:\n    reports = session.sql(\"LIST @DG_RAW_TST_DB.DG.HTML/report/\").collect()\n    report_files = [row['name'].split('/')[-1] for row in reports if row['name'].endswith('.html')]\nexcept Exception as e:\n    st.error(f\"Failed to list reports: {str(e)}\")\n    report_files = []\n\nif report_files:\n    # Dropdown to select a report\n    selected_report = st.selectbox(\"Select a report to view\", report_files)\n\n    if selected_report:\n        # Get the HTML content\n        html_content, error = get_html_content(f\"report/{selected_report}\")\n        \n        if error:\n            st.error(error)\n        elif html_content:\n            # Display options\n            display_option = st.radio(\"Choose display option:\", [\"View as text\", \"View rendered HTML\"])\n            \n            if display_option == \"View as text\":\n                st.text_area(\"HTML Content\", html_content, height=400)\n            else:\n                st.markdown(html_content, unsafe_allow_html=True)\n\n            # Provide a download button\n            b64 = base64.b64encode(html_content.encode()).decode()\n            href = f'<a href=\"data:text/html;base64,{b64}\" download=\"{selected_report}\">Download HTML file</a>'\n            st.markdown(href, unsafe_allow_html=True)\n        else:\n            st.warning(\"No content found in the selected report.\")\nelse:\n    st.warning(\"No reports found in the specified stage.\")\n\n# Display Streamlit version\nst.sidebar.text(f\"Streamlit version: {st.__version__}\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1c6b0cee-8594-4342-8201-ac8dea8867fd",
   "metadata": {
    "language": "python",
    "name": "cell20"
   },
   "outputs": [],
   "source": "tests = TestSuite(tests=[\n    TestNumberOfColumnsWithMissingValues(),\n    TestNumberOfRowsWithMissingValues(),\n    TestNumberOfConstantColumns(),\n    TestNumberOfDuplicatedRows(),\n    TestNumberOfDuplicatedColumns(),\n    TestColumnsType(),\n    TestNumberOfDriftedColumns(),\n])\n\ntests.run(reference_data=reference, current_data=current)\ntests",
   "execution_count": null
  }
 ]
}